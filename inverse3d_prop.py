import cv2
import numpy as np
import torch
from torch import nn
from tqdm import tqdm
from unet import UnetGenerator, init_weights
import utils
from torchsummary import summary
import prop_ideal

from torchvision.transforms.functional import gaussian_blur


class UNetProp(nn.Module):
    def __init__(self, img_size, input_nc, output_nc, num_downs=8, norm=nn.InstanceNorm2d) -> None:
        super().__init__()
        
        num_downs = num_downs
        num_feats_min = 32
        num_feats_max = 512
        norm = norm
        self.unet = UnetGenerator(input_nc=input_nc, output_nc=output_nc,
                                    num_downs=num_downs, nf0=num_feats_min,
                                    max_channels=num_feats_max, norm_layer=norm, outer_skip=True)
        init_weights(self.unet, init_type='normal')
        
        self.img_size = img_size
        # the input size has to be the multiple of 2**num_downs for unet
        multiple = 2**num_downs
        self.reshape_size = ((img_size[0] + multiple - 1) // multiple * multiple, (img_size[1] + multiple - 1) // multiple * multiple)
    
    def forward(self, input):
        
        input = utils.pad_image(input, target_shape=self.reshape_size, pytorch=True, stacked_complex=False)
        input = utils.crop_image(input, target_shape=self.reshape_size, pytorch=True, stacked_complex=False)
        
        unet_output = self.unet(input)
        
        unet_output = utils.pad_image(unet_output, target_shape=self.img_size, pytorch=True, stacked_complex=False)
        unet_output = utils.crop_image(unet_output, target_shape=self.img_size, pytorch=True, stacked_complex=False)

        return unet_output


class InversePropagation(nn.Module):
    def __init__(self, inverse_network_config, **kwargs):
        super().__init__()
        self.config = inverse_network_config
        if self.config == 'cnn_only':
            self.inverse_cnn = UNetProp(img_size=kwargs['image_res'], input_nc=len(kwargs['prop_dists_from_wrp']), output_nc=1, num_downs=4)
            self.forward = self.inverse_CNN_only
        elif self.config == 'unetasmunet':
            self.target_cnn = UNetProp(img_size=kwargs['image_res'], input_nc=len(kwargs['prop_dists_from_wrp']), output_nc=2, num_downs=4)
            self.inverse_asm = prop_ideal.SerialProp(-kwargs['prop_dist'], kwargs['wavelength'], kwargs['feature_size'],
                                        'ASM', kwargs['F_aperture'], None,
                                        dim=1)
            self.slm_cnn = UNetProp(img_size=kwargs['image_res'], input_nc=2, output_nc=2, num_downs=4)
            # self.slm_cnn = ResNet_Prop(input_channel=2, output_channel=2, block_num=8)
            self.forward = self.inverse_CNN_ASM_CNN
        else:
            raise ValueError(f'{inverse_network_config} not implemented!')
        
    def inverse_CNN_only(self, masked_imgs):
        ########## phase generated by CNN only ###################        
        slm_phase = self.inverse_cnn(masked_imgs)
        ##########################################################
        return slm_phase

    def inverse_CNN_ASM_CNN(self, masked_imgs):
        ########## phase generated by CNN+ASM+CNN ###############
        # mid_amp_phase = self.target_cnn(masked_imgs)
        # mid_amp = mid_amp_phase[:,0:1,:,:]
        # mid_phase = mid_amp_phase[:,1:2,:,:]
        # mid_field = torch.complex(mid_amp * torch.cos(mid_phase), mid_amp * torch.sin(mid_phase))
        # slm_field = self.inverse_asm(mid_field)
        # slm_phase = self.slm_cnn(torch.cat([slm_field.abs(), slm_field.angle()], dim=1))
        # ##########################################################
        # return slm_phase
        mid_real_imag = self.target_cnn(masked_imgs)
        mid_real = mid_real_imag[:,0:1,:,:]
        mid_imag = mid_real_imag[:,1:2,:,:]
        mid_field = torch.complex(mid_real, mid_imag)
        slm_field = self.inverse_asm(mid_field)
        slm_real_imag = self.slm_cnn(torch.cat([slm_field.real, slm_field.imag], dim=1))
        
        slm_real = slm_real_imag[:,0:1,:,:]
        slm_imag = slm_real_imag[:,1:2,:,:]
        # slm_field = torch.complex(slm_real, slm_imag)
        slm_real = gaussian_blur(slm_real, kernel_size=5)
        slm_imag = gaussian_blur(slm_imag, kernel_size=5)

        slm_phase = torch.atan2(slm_imag, slm_real)
        ##########################################################
        return slm_phase